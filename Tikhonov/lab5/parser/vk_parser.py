import requests
import time
import json
import re
from sqlalchemy import create_engine, text

# --- –ù–ê–°–¢–†–û–ô–ö–ò ---
# –¢–≤–æ–π –Ω–æ–≤—ã–π —Ç–æ–∫–µ–Ω (—É–∂–µ –≤—Å—Ç–∞–≤–ª–µ–Ω)
TOKEN = 'vk1.a.0Jt3n6AwGKES2sfJD2P76XbMkoAk4cMaqfNXnZL0kGRDGSdwvOuF--2rqhoY_xHjwRSBfCzPN8tlvihcNnVkA8XhDb_9cjw_Rd94YycTxdQ6b0bnChaqmNck95YkJ_pM1opuaj3D43sLLy1ijH1pEHcGwn8zTkdllgB0botCOQvffTud2JcJr0l7m-fdkev_EjpwWXujXd89vzL1YbH8xg'
VERSION = '5.131'

# –¢–≤–æ–∏ ID –≥—Ä—É–ø–ø (—Å–∫—Ä–∏–ø—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –¥–µ–ª–∞–µ—Ç –∏—Ö –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–º–∏ –¥–ª—è –æ–±—Ä–∞—â–µ–Ω–∏—è –∫ —Å—Ç–µ–Ω–∞–º)
RAW_IDS = [
    60246922, 27838907, 108494404, 125528525, 63677604,
    66394898, 161456272, 193336088, 73133102, 5421782,
    199588232, 167467761, 212986781, 166718171, 190831704
]
GROUP_IDS = [-abs(gid) for gid in RAW_IDS]

# –ê–∫—Ç—É–∞–ª—å–Ω–∞—è –∫–∞—Ä—Ç–∞ –ª–æ–∫–∞—Ü–∏–π –ê—Ä–∑–∞–º–∞—Å–∞
LOCATION_MAP = {
    r"–∫–∞–ª–∏–Ω": "–ö–∞–ª–∏–Ω–∏–Ω–∞",
    r"–ª–µ–Ω–∏–Ω": "–õ–µ–Ω–∏–Ω–∞",
    r"–º–∞—Ä–∫—Å": "–ú–∞—Ä–∫—Å–∞",
    r"–æ–º–µ–≥": "–¢–¶ –û–º–µ–≥–∞",
    r"–ø–ª–∞–∑": "–¢–¶ –ü–ª–∞–∑–∞",
    r"–∫—É–±": "–¢–¶ –ö—É–±",
    r"(–∞–≤–µ–Ω—é|avenu)": "–¢–¶ –ê–≤–µ–Ω—é",
    r"–≥–∞–π–¥–∞—Ä": "–ü–∞—Ä–∫ –ì–∞–π–¥–∞—Ä–∞",
    r"—Å–æ–±–æ—Ä–Ω": "–°–æ–±–æ—Ä–Ω–∞—è",
    r"–≤–æ–∫–∑–∞–ª": "–í–æ–∫–∑–∞–ª",
    r"–ø–ª–∞–Ω–¥–∏–Ω": "–ü–ª–∞–Ω–¥–∏–Ω–∞",
    r"9 –º–∞—è": "9 –ú–∞—è",
    r"–ø–∞—Ä–∫–æ–≤–∞—è": "–ü–∞—Ä–∫–æ–≤–∞—è",
    r"–ø—É—à–∫–∏–Ω": "–ü—É—à–∫–∏–Ω–∞",
    r"–º–∏—Ä–∞": "–ú–∏—Ä–∞",
    r"—Å–æ–≤–µ—Ç—Å–∫": "–°–æ–≤–µ—Ç—Å–∫–∞—è",
    r"—Å–µ–≤–∞—Å—Ç–æ–ø–æ–ª—å": "–°–µ–≤–∞—Å—Ç–æ–ø–æ–ª—å—Å–∫–∞—è",
    r"–∫–∏—Ä–∏–ª–ª": "–ö–∏—Ä–∏–ª–ª–æ–≤–∫–∞",
    r"–≤—ã–µ–∑–¥–Ω": "–í—ã–µ–∑–¥–Ω–æ–µ",
    r"–≥–æ—Ä—å–∫–æ": "–ì–æ—Ä—å–∫–æ–≥–æ",
    r"–ø—Ä–æ—Å–ø–µ–∫—Ç": "–ü—Ä–æ—Å–ø–µ–∫—Ç"
}

engine = create_engine("postgresql://admin:admin@localhost:5432/arzamas_radar")


def get_posts(group_id, offset):
    url = 'https://api.vk.com/method/wall.get'
    params = {
        'access_token': TOKEN,
        'v': VERSION,
        'owner_id': group_id,
        'count': 50,
        'offset': offset
    }
    try:
        resp = requests.get(url, params=params).json()
        if 'error' in resp:
            return f"‚ùå –û–®–ò–ë–ö–ê –í–ö: {resp['error']['error_msg']}"
        return resp.get('response', {}).get('items', [])
    except Exception as e:
        return f"‚ùå –°–ë–û–ô –°–ï–¢–ò: {str(e)}"


def save_post(post, gid):
    text_content = post.get('text', '')
    if not text_content: return False

    # –ü–æ–∏—Å–∫ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π –ø–æ –∫–ª—é—á–∞–º —É–ª–∏—Ü –∏ –¢–¶
    found_locs = []
    for pattern, official in LOCATION_MAP.items():
        if re.search(pattern, text_content, re.IGNORECASE):
            found_locs.append(official)

    if not found_locs:
        return False

        # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –Ω–∞–∑–≤–∞–Ω–∏–π (–Ω–∞–ø—Ä–∏–º–µ—Ä, –µ—Å–ª–∏ "–õ–µ–Ω–∏–Ω–∞" –≤—Å—Ç—Ä–µ—Ç–∏–ª–æ—Å—å –¥–≤–∞–∂–¥—ã)
    found_locs = list(set(found_locs))

    try:
        with engine.connect() as conn:
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –¥—É–±–ª–∏–∫–∞—Ç —Å–∞–º–æ–≥–æ –ø–æ—Å—Ç–∞ –≤ –±–∞–∑–µ
            dup = conn.execute(text("SELECT 1 FROM news_posts WHERE post_text = :t LIMIT 1"),
                               {"t": text_content}).fetchone()
            if dup: return False

            # –î–µ—Ç–µ–∫—Ç–æ—Ä —Ä–µ–∫–ª–∞–º—ã
            is_ads = post.get('marked_as_ads') or any(
                x in text_content.lower() for x in ["—Ü–µ–Ω–∞", "—Å–∫–∏–¥–∫–∞", "—Ä–µ–∫–ª–∞–º–∞", "–∑–∞–ø–∏—Å—å", "—Ç–æ–≤–∞—Ä"])

            conn.execute(
                text("INSERT INTO news_posts (post_text, locations, post_type) VALUES (:t, :l, :tp)"),
                {"t": text_content, "l": json.dumps(found_locs), "tp": "–†–µ–∫–ª–∞–º–∞" if is_ads else "–°–æ–±—ã—Ç–∏–µ"}
            )
            conn.commit()

            # –ü–µ—á–∞—Ç–∞–µ–º —É—Å–ø–µ—Ö –≤ –∫–æ–Ω—Å–æ–ª—å
            preview = text_content[:60].replace('\n', ' ')
            print(f"‚úÖ [ID:{gid}] –ù–∞–π–¥–µ–Ω–æ: {found_locs} | –¢–µ–∫—Å—Ç: {preview}...")
            return True
    except:
        return False


def run_harvester(target=10000):
    with engine.connect() as conn:
        db_total = conn.execute(text("SELECT count(*) FROM news_posts")).scalar()

    print(f"üöÄ –°–¢–ê–†–¢ –ü–ê–†–°–ò–ù–ì–ê –ê–†–ó–ê–ú–ê–°–ê. –í –±–∞–∑–µ: {db_total}. –¶–µ–ª—å: {target}")

    offset = 0
    added_session = 0

    while (db_total + added_session) < target and offset < 100000:
        print(f"\n--- –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏—Å—Ç–æ—Ä–∏–∏ –Ω–∞ –≥–ª—É–±–∏–Ω–µ {offset} –ø–æ—Å—Ç–æ–≤ ---")
        any_posts_at_level = False

        for gid in GROUP_IDS:
            posts = get_posts(gid, offset)

            # –ï—Å–ª–∏ –≤–µ—Ä–Ω—É–ª–∞—Å—å —Å—Ç—Ä–æ–∫–∞ (–æ—à–∏–±–∫–∞), –ø–µ—á–∞—Ç–∞–µ–º –µ—ë
            if isinstance(posts, str):
                print(f"   {posts} (–ì—Ä—É–ø–ø–∞ {gid})")
                continue

            if not posts:
                continue

            any_posts_at_level = True
            for p in posts:
                if save_post(p, gid):
                    added_session += 1

            # –ü–∞—É–∑–∞ –¥–ª—è –æ–±—Ö–æ–¥–∞ –∞–Ω—Ç–∏-—Å–ø–∞–º —Ñ–∏–ª—å—Ç—Ä–∞ –í–ö
            time.sleep(0.35)

        if not any_posts_at_level and offset > 5000:
            print("üèÅ –ü–æ—Å—Ç—ã –≤–æ –≤—Å–µ—Ö –≥—Ä—É–ø–ø–∞—Ö –∑–∞–∫–æ–Ω—á–∏–ª–∏—Å—å.")
            break

        offset += 50
        print(f"üìä –î–æ–±–∞–≤–ª–µ–Ω–æ –∑–∞ —Å–µ—Å—Å–∏—é: {added_session} | –í—Å–µ–≥–æ –≤ –ë–î: {db_total + added_session}")


if __name__ == "__main__":
    run_harvester()